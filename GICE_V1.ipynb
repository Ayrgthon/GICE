{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma final de las secuencias: torch.Size([55, 133, 21, 3])\n",
      "Ejemplo de etiquetas: ['chau', 'chau', 'chau', 'chau', 'chau', 'chau', 'chau', 'chau', 'chau', 'chau', 'chau', 'chau', 'chau', 'chau', 'chau', 'chau', 'hola', 'hola', 'hola', 'hola', 'hola', 'hola', 'hola', 'hola', 'hola', 'hola', 'hola', 'hola', 'hola', 'hola', 'hola', 'hola', 'hola', 'hola', 'hola', 'hola', 'hola', 'hola', 'hola', 'gracias', 'gracias', 'gracias', 'gracias', 'gracias', 'gracias', 'gracias', 'gracias', 'gracias', 'gracias', 'gracias', 'gracias', 'gracias', 'gracias', 'gracias', 'gracias']\n",
      "X_train shape: torch.Size([44, 133, 21, 3])\n",
      "y_train shape: torch.Size([44])\n",
      "X_val shape: torch.Size([11, 133, 21, 3])\n",
      "y_val shape: torch.Size([11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sorac\\AppData\\Local\\Temp\\ipykernel_15600\\2968384753.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped = df_total.groupby(\"Secuencia\").apply(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "df_chau    = pd.read_csv(\"chau.csv\")\n",
    "df_hola    = pd.read_csv(\"hola.csv\")\n",
    "df_gracias = pd.read_csv(\"gracias.csv\")\n",
    "df_chau[\"label\"]    = \"chau\"\n",
    "df_hola[\"label\"]    = \"hola\"\n",
    "df_gracias[\"label\"] = \"gracias\"\n",
    "max_seq_chau = df_chau[\"Secuencia\"].max() \n",
    "df_hola[\"Secuencia\"] = df_hola[\"Secuencia\"] + max_seq_chau\n",
    "max_seq_hola = df_hola[\"Secuencia\"].max()\n",
    "df_gracias[\"Secuencia\"] = df_gracias[\"Secuencia\"] + max_seq_hola\n",
    "df_total = pd.concat([df_chau, df_hola, df_gracias], ignore_index=True)\n",
    "grouped = df_total.groupby(\"Secuencia\").apply(\n",
    "    lambda x: torch.tensor(x[[\"X\", \"Y\", \"Z\"]].values, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "all_tensors = grouped.tolist() \n",
    "padded = pad_sequence(all_tensors, batch_first=True)\n",
    "\n",
    "num_sequences = padded.shape[0]\n",
    "max_len = padded.shape[1]\n",
    "\n",
    "if max_len % 21 != 0:\n",
    "    raise ValueError(\n",
    "        \"La secuencia más larga no es múltiplo de 21. \"\n",
    "        \"Verifica que tus datos estén ordenados y agrupen 21 puntos por frame.\"\n",
    "    )\n",
    "\n",
    "T_max = max_len // 21\n",
    "padded = padded.reshape(num_sequences, T_max, 21, 3)\n",
    "print(\"Forma final de las secuencias:\", padded.shape)\n",
    "labels = df_total.groupby(\"Secuencia\")[\"label\"].first().tolist()\n",
    "print(\"Ejemplo de etiquetas:\", labels)\n",
    "label_map = {\"chau\": 0, \"hola\": 1, \"gracias\": 2}\n",
    "y_total = [label_map[l] for l in labels]\n",
    "y_total = torch.tensor(y_total, dtype=torch.long)\n",
    "indices = torch.randperm(num_sequences)\n",
    "train_size = int(0.8 * num_sequences)\n",
    "train_indices = indices[:train_size]\n",
    "val_indices   = indices[train_size:]\n",
    "\n",
    "X_train = padded[train_indices]\n",
    "y_train = y_total[train_indices]\n",
    "X_val   = padded[val_indices]\n",
    "y_val   = y_total[val_indices]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Secuencia</th>\n",
       "      <th>Mano</th>\n",
       "      <th>Punto</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Derecha</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193509</td>\n",
       "      <td>0.916309</td>\n",
       "      <td>1.562929e-07</td>\n",
       "      <td>chau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Derecha</td>\n",
       "      <td>1</td>\n",
       "      <td>0.247191</td>\n",
       "      <td>0.919252</td>\n",
       "      <td>-3.174349e-03</td>\n",
       "      <td>chau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Derecha</td>\n",
       "      <td>2</td>\n",
       "      <td>0.299474</td>\n",
       "      <td>0.905067</td>\n",
       "      <td>-1.362301e-02</td>\n",
       "      <td>chau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Derecha</td>\n",
       "      <td>3</td>\n",
       "      <td>0.343559</td>\n",
       "      <td>0.896575</td>\n",
       "      <td>-2.491510e-02</td>\n",
       "      <td>chau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Derecha</td>\n",
       "      <td>4</td>\n",
       "      <td>0.372926</td>\n",
       "      <td>0.887576</td>\n",
       "      <td>-3.939677e-02</td>\n",
       "      <td>chau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25405</th>\n",
       "      <td>16</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>16</td>\n",
       "      <td>0.495591</td>\n",
       "      <td>0.905821</td>\n",
       "      <td>-8.143111e-02</td>\n",
       "      <td>chau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25406</th>\n",
       "      <td>16</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>17</td>\n",
       "      <td>0.529466</td>\n",
       "      <td>1.029239</td>\n",
       "      <td>-5.783628e-02</td>\n",
       "      <td>chau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25407</th>\n",
       "      <td>16</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>18</td>\n",
       "      <td>0.536592</td>\n",
       "      <td>1.006084</td>\n",
       "      <td>-7.537854e-02</td>\n",
       "      <td>chau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25408</th>\n",
       "      <td>16</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>19</td>\n",
       "      <td>0.539670</td>\n",
       "      <td>0.985539</td>\n",
       "      <td>-8.088870e-02</td>\n",
       "      <td>chau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25409</th>\n",
       "      <td>16</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>20</td>\n",
       "      <td>0.539530</td>\n",
       "      <td>0.964231</td>\n",
       "      <td>-8.517770e-02</td>\n",
       "      <td>chau</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25410 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Secuencia       Mano  Punto         X         Y             Z label\n",
       "0              1    Derecha      0  0.193509  0.916309  1.562929e-07  chau\n",
       "1              1    Derecha      1  0.247191  0.919252 -3.174349e-03  chau\n",
       "2              1    Derecha      2  0.299474  0.905067 -1.362301e-02  chau\n",
       "3              1    Derecha      3  0.343559  0.896575 -2.491510e-02  chau\n",
       "4              1    Derecha      4  0.372926  0.887576 -3.939677e-02  chau\n",
       "...          ...        ...    ...       ...       ...           ...   ...\n",
       "25405         16  Izquierda     16  0.495591  0.905821 -8.143111e-02  chau\n",
       "25406         16  Izquierda     17  0.529466  1.029239 -5.783628e-02  chau\n",
       "25407         16  Izquierda     18  0.536592  1.006084 -7.537854e-02  chau\n",
       "25408         16  Izquierda     19  0.539670  0.985539 -8.088870e-02  chau\n",
       "25409         16  Izquierda     20  0.539530  0.964231 -8.517770e-02  chau\n",
       "\n",
       "[25410 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura por defecto de STGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points_per_frame = 21\n",
    "\n",
    "adjacency_matrix = np.zeros((num_points_per_frame, num_points_per_frame), dtype=int)\n",
    "edges = [\n",
    "    (0, 1), (1, 2), (2, 3), (3, 4),\n",
    "    (0, 5), (5, 6), (6, 7), (7, 8),\n",
    "    (5, 9) , (9, 10), (10, 11), (11, 12),\n",
    "    (9, 13), (13, 14), (14, 15), (15, 16),\n",
    "    (0, 17), (17, 18), (18, 19), (19, 20),\n",
    "    (13, 17)\n",
    "]\n",
    "for edge in edges:\n",
    "    adjacency_matrix[edge[0], edge[1]] = 1\n",
    "    adjacency_matrix[edge[1], edge[0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.fc = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, X, A):\n",
    "        batch_size, num_nodes, in_features, time_steps = X.shape\n",
    "\n",
    "        X = X.permute(0, 3, 1, 2)  # (batch_size, time_steps, num_nodes, in_features)\n",
    "        X = X.reshape(batch_size * time_steps, num_nodes, in_features)\n",
    "\n",
    "        if A.ndim == 2:\n",
    "            # Caso A fija para todos\n",
    "            A = A.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "            A = A.repeat(time_steps, 1, 1)\n",
    "        elif A.ndim == 3:\n",
    "            # Caso A viene con forma (batch_size, num_nodes, num_nodes)\n",
    "            # Hay que expandirla al eje del tiempo\n",
    "            # => (batch_size, time_steps, num_nodes, num_nodes)\n",
    "            A = A.unsqueeze(1).expand(-1, time_steps, -1, -1)\n",
    "            # => (batch_size * time_steps, num_nodes, num_nodes)\n",
    "            A = A.reshape(batch_size * time_steps, num_nodes, num_nodes)\n",
    "        else:\n",
    "            raise ValueError(\"Dimensión de A no soportada.\")\n",
    "\n",
    "        # Multiplicación batch-wise\n",
    "        out = torch.bmm(A, X)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        # Restaurar dimensiones\n",
    "        out = out.reshape(batch_size, time_steps, num_nodes, -1)\n",
    "        return out.permute(0, 2, 3, 1)\n",
    "\n",
    "\n",
    "class TemporalConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Temporal convolution using Conv1D.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super(TemporalConv, self).__init__()\n",
    "        self.conv1d = nn.Conv2d(in_channels, out_channels, kernel_size=(kernel_size, 1), padding=(kernel_size // 2, 0))\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - X: (batch_size, num_nodes, in_channels, time_steps)\n",
    "        \"\"\"\n",
    "        X = X.permute(0, 2, 1, 3)  # (batch_size, in_channels, num_nodes, time_steps)\n",
    "        out = self.conv1d(X)  # Apply temporal convolution\n",
    "        return out.permute(0, 2, 1, 3)  # Back to (batch_size, num_nodes, out_channels, time_steps)\n",
    "\n",
    "\n",
    "class STBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Spatio-Temporal Block: Combines temporal and spatial convolutions.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, num_nodes, kernel_size=3):\n",
    "        super(STBlock, self).__init__()\n",
    "        self.temporal1 = TemporalConv(in_channels, out_channels, kernel_size)\n",
    "        self.graph_conv = GraphConv(out_channels, out_channels)\n",
    "        self.temporal2 = TemporalConv(out_channels, out_channels, kernel_size)\n",
    "        self.norm = nn.LayerNorm([out_channels, num_nodes])  # Normalize along features and nodes\n",
    "\n",
    "    def forward(self, X, A):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - X: (batch_size, num_nodes, in_channels, time_steps)\n",
    "        - A: (num_nodes, num_nodes)\n",
    "        \"\"\"\n",
    "        out = F.relu(self.temporal1(X))\n",
    "        out = self.graph_conv(out, A)\n",
    "        out = self.temporal2(out)\n",
    "        out = out.permute(0, 3, 2, 1)  # (batch_size, time_steps, features, nodes)\n",
    "        out = self.norm(out)  # Normalize features and nodes\n",
    "        return out.permute(0, 3, 2, 1)  # Back to (batch_size, num_nodes, features, time_steps)\n",
    "\n",
    "\n",
    "class STGCN(nn.Module):\n",
    "    def __init__(self, num_nodes, in_channels, hidden_channels, num_classes, kernel_size=3):\n",
    "        super(STGCN, self).__init__()\n",
    "        self.block1 = STBlock(in_channels, hidden_channels, num_nodes, kernel_size)\n",
    "        self.block2 = STBlock(hidden_channels, hidden_channels, num_nodes, kernel_size)\n",
    "        self.fc = nn.Linear(hidden_channels, num_classes)  # Salida con el número de clases\n",
    "        self.num_nodes = num_nodes\n",
    "\n",
    "    def forward(self, X, A):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - X: (batch_size, num_frames, num_nodes, num_features) --> Ajustado a (batch_size, num_nodes, num_features, num_frames)\n",
    "        - A: (num_nodes, num_nodes)\n",
    "        \"\"\"\n",
    "        # Ajustar dimensiones de entrada\n",
    "        X = X.permute(0, 2, 3, 1)  # (batch_size, num_nodes, num_features, num_frames)\n",
    "        \n",
    "        # Pasar por bloques STGCN\n",
    "        out = self.block1(X, A)\n",
    "        out = self.block2(out, A)\n",
    "        \n",
    "        # Pooling sobre nodos y tiempo\n",
    "        out = out.mean(dim=1)  # (batch_size, num_features, time_steps)\n",
    "        out = out.mean(dim=-1)  # (batch_size, hidden_channels)\n",
    "\n",
    "        # Clasificación final\n",
    "        out = self.fc(out)  # (batch_size, num_classes)\n",
    "        return out\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, X_data, y_data, adjacency_matrix):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - X_data: Tensor con forma (num_sequences, num_frames, num_nodes, num_features)\n",
    "        - y_data: Lista de etiquetas con forma (num_sequences,)\n",
    "        - adjacency_matrix: Matriz de adyacencia con forma (num_nodes, num_nodes)\n",
    "        \"\"\"\n",
    "        self.X_data = torch.tensor(X_data, dtype=torch.float32)\n",
    "        self.y_data = torch.tensor(y_data, dtype=torch.long)\n",
    "        self.adjacency_matrix = torch.tensor(adjacency_matrix, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Devuelve los datos de entrada y etiqueta para un índice específico.\n",
    "        \"\"\"\n",
    "        X = self.X_data[idx]  # (num_frames, num_nodes, num_features)\n",
    "        y = self.y_data[idx]  # Etiqueta\n",
    "        A = self.adjacency_matrix  # Matriz de adyacencia (constante para todos)\n",
    "        return X, y, A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sorac\\AppData\\Local\\Temp\\ipykernel_17488\\3390574583.py:123: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.X_data = torch.tensor(X_data, dtype=torch.float32)\n",
      "C:\\Users\\sorac\\AppData\\Local\\Temp\\ipykernel_17488\\3390574583.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.y_data = torch.tensor(y_data, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "dataset = SequenceDataset(X_train, y_train, adjacency_matrix)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "num_nodes = 21\n",
    "num_features = 3\n",
    "hidden_channels = 64 * 3\n",
    "num_classes = 3  # Hola / Chau / gracias\n",
    "model = STGCN(num_nodes, num_features, hidden_channels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X_batch: torch.Size([4, 22, 21, 3])\n",
      "Forma de y_batch: torch.Size([4])\n",
      "Forma de A_batch: torch.Size([4, 21, 21])\n",
      "tensor([2, 0, 1, 1])\n",
      "Forward pass exitoso!\n",
      "Forma de salida (y_pred): torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# Simular un lote del DataLoader\n",
    "for X_batch, y_batch, A_batch in dataloader:\n",
    "    print(\"Forma de X_batch:\", X_batch.shape)  # (batch_size, num_frames, num_nodes, num_features)\n",
    "    print(\"Forma de y_batch:\", y_batch.shape)  # (batch_size,)\n",
    "    print(\"Forma de A_batch:\", A_batch.shape)  # (num_nodes, num_nodes)\n",
    "    print(y_batch)\n",
    "    \n",
    "    y_pred = model(X_batch, A_batch)  # Forward pass\n",
    "    print(\"Forward pass exitoso!\")\n",
    "    print(\"Forma de salida (y_pred):\", y_pred.shape)  # (batch_size, num_classes)\n",
    "    \n",
    "    break  # Solo probar un lote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sorac\\AppData\\Local\\Temp\\ipykernel_17488\\3390574583.py:123: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.X_data = torch.tensor(X_data, dtype=torch.float32)\n",
      "C:\\Users\\sorac\\AppData\\Local\\Temp\\ipykernel_17488\\3390574583.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.y_data = torch.tensor(y_data, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SequenceDataset(X_train, y_train, adjacency_matrix) \n",
    "val_dataset = SequenceDataset(X_val, y_val, adjacency_matrix)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "num_nodes = 21\n",
    "num_features = 3\n",
    "hidden_channels = 64 * 5\n",
    "num_classes = 3 \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = STGCN(num_nodes, num_features, hidden_channels, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, A_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            A_batch = A_batch.to(device)\n",
    "\n",
    "            outputs = model(X_batch, A_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    return val_loss, all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200]: Train Loss: 1.4623  |  Val Loss: 1.1430\n",
      "Epoch [2/200]: Train Loss: 1.1592  |  Val Loss: 1.1073\n",
      "Epoch [3/200]: Train Loss: 1.1947  |  Val Loss: 1.1080\n",
      "Epoch [4/200]: Train Loss: 1.1674  |  Val Loss: 1.1013\n",
      "Epoch [5/200]: Train Loss: 1.1441  |  Val Loss: 1.1626\n",
      "Epoch [6/200]: Train Loss: 1.1928  |  Val Loss: 1.1212\n",
      "Epoch [7/200]: Train Loss: 1.1477  |  Val Loss: 1.1443\n",
      "Epoch [8/200]: Train Loss: 1.1258  |  Val Loss: 1.1096\n",
      "Epoch [9/200]: Train Loss: 1.1179  |  Val Loss: 1.3034\n",
      "Epoch [10/200]: Train Loss: 1.1648  |  Val Loss: 1.1020\n",
      "Epoch [11/200]: Train Loss: 1.1108  |  Val Loss: 1.1061\n",
      "Epoch [12/200]: Train Loss: 1.1163  |  Val Loss: 1.0857\n",
      "Epoch [13/200]: Train Loss: 1.1037  |  Val Loss: 1.0878\n",
      "Epoch [14/200]: Train Loss: 1.0771  |  Val Loss: 1.0941\n",
      "Epoch [15/200]: Train Loss: 1.0664  |  Val Loss: 1.1006\n",
      "Epoch [16/200]: Train Loss: 1.0706  |  Val Loss: 1.1007\n",
      "Epoch [17/200]: Train Loss: 1.0688  |  Val Loss: 1.1086\n",
      "Epoch [18/200]: Train Loss: 1.0768  |  Val Loss: 1.1095\n",
      "Epoch [19/200]: Train Loss: 1.0608  |  Val Loss: 1.0047\n",
      "Epoch [20/200]: Train Loss: 1.0179  |  Val Loss: 0.9711\n",
      "Epoch [21/200]: Train Loss: 1.0276  |  Val Loss: 1.1680\n",
      "Epoch [22/200]: Train Loss: 1.0352  |  Val Loss: 1.0039\n",
      "Epoch [23/200]: Train Loss: 1.0222  |  Val Loss: 0.9755\n",
      "Epoch [24/200]: Train Loss: 1.0002  |  Val Loss: 0.9811\n",
      "Epoch [25/200]: Train Loss: 1.0876  |  Val Loss: 0.9347\n",
      "Epoch [26/200]: Train Loss: 0.9818  |  Val Loss: 1.0293\n",
      "Epoch [27/200]: Train Loss: 0.9565  |  Val Loss: 0.9108\n",
      "Epoch [28/200]: Train Loss: 0.9226  |  Val Loss: 0.9594\n",
      "Epoch [29/200]: Train Loss: 0.9400  |  Val Loss: 1.0067\n",
      "Epoch [30/200]: Train Loss: 0.8816  |  Val Loss: 0.9372\n",
      "Epoch [31/200]: Train Loss: 0.8633  |  Val Loss: 0.8842\n",
      "Epoch [32/200]: Train Loss: 0.7988  |  Val Loss: 0.7888\n",
      "Epoch [33/200]: Train Loss: 0.9361  |  Val Loss: 0.7946\n",
      "Epoch [34/200]: Train Loss: 0.7822  |  Val Loss: 0.7898\n",
      "Epoch [35/200]: Train Loss: 0.8006  |  Val Loss: 1.0295\n",
      "Epoch [36/200]: Train Loss: 0.7615  |  Val Loss: 0.8785\n",
      "Epoch [37/200]: Train Loss: 0.7524  |  Val Loss: 0.9025\n",
      "Epoch [38/200]: Train Loss: 0.6919  |  Val Loss: 0.8307\n",
      "Epoch [39/200]: Train Loss: 0.6456  |  Val Loss: 1.1309\n",
      "Epoch [40/200]: Train Loss: 0.8342  |  Val Loss: 0.9973\n",
      "Epoch [41/200]: Train Loss: 0.6346  |  Val Loss: 0.7961\n",
      "Epoch [42/200]: Train Loss: 0.6213  |  Val Loss: 0.8409\n",
      "Epoch [43/200]: Train Loss: 0.7144  |  Val Loss: 0.8215\n",
      "Epoch [44/200]: Train Loss: 0.6290  |  Val Loss: 0.8746\n",
      "Epoch [45/200]: Train Loss: 0.6387  |  Val Loss: 0.7695\n",
      "Epoch [46/200]: Train Loss: 0.5063  |  Val Loss: 0.7812\n",
      "Epoch [47/200]: Train Loss: 0.4676  |  Val Loss: 0.7842\n",
      "Epoch [48/200]: Train Loss: 0.6431  |  Val Loss: 0.7205\n",
      "Epoch [49/200]: Train Loss: 0.4496  |  Val Loss: 0.7490\n",
      "Epoch [50/200]: Train Loss: 0.5435  |  Val Loss: 0.9191\n",
      "Epoch [51/200]: Train Loss: 0.4834  |  Val Loss: 0.7818\n",
      "Epoch [52/200]: Train Loss: 0.4596  |  Val Loss: 0.7688\n",
      "Epoch [53/200]: Train Loss: 0.4393  |  Val Loss: 0.7553\n",
      "Epoch [54/200]: Train Loss: 0.4349  |  Val Loss: 0.8149\n",
      "Epoch [55/200]: Train Loss: 0.4342  |  Val Loss: 0.7409\n",
      "Epoch [56/200]: Train Loss: 0.3738  |  Val Loss: 0.8900\n",
      "Epoch [57/200]: Train Loss: 0.3241  |  Val Loss: 0.7943\n",
      "Epoch [58/200]: Train Loss: 0.3952  |  Val Loss: 0.8387\n",
      "Epoch [59/200]: Train Loss: 0.4393  |  Val Loss: 0.8797\n",
      "Epoch [60/200]: Train Loss: 0.4070  |  Val Loss: 0.7628\n",
      "Epoch [61/200]: Train Loss: 0.2827  |  Val Loss: 0.8797\n",
      "Epoch [62/200]: Train Loss: 0.3387  |  Val Loss: 0.7967\n",
      "Epoch [63/200]: Train Loss: 0.2490  |  Val Loss: 0.9139\n",
      "Epoch [64/200]: Train Loss: 0.2400  |  Val Loss: 0.7817\n",
      "Epoch [65/200]: Train Loss: 0.2672  |  Val Loss: 0.8784\n",
      "Epoch [66/200]: Train Loss: 0.4094  |  Val Loss: 0.8504\n",
      "Epoch [67/200]: Train Loss: 0.8083  |  Val Loss: 0.9271\n",
      "Epoch [68/200]: Train Loss: 0.4802  |  Val Loss: 0.9782\n",
      "Epoch [69/200]: Train Loss: 0.3430  |  Val Loss: 0.8663\n",
      "Epoch [70/200]: Train Loss: 0.4398  |  Val Loss: 0.7981\n",
      "Epoch [71/200]: Train Loss: 0.3275  |  Val Loss: 0.8239\n",
      "Epoch [72/200]: Train Loss: 0.2889  |  Val Loss: 0.7916\n",
      "Epoch [73/200]: Train Loss: 0.2326  |  Val Loss: 0.7513\n",
      "Epoch [74/200]: Train Loss: 0.2893  |  Val Loss: 0.7802\n",
      "Epoch [75/200]: Train Loss: 0.2907  |  Val Loss: 0.9519\n",
      "Epoch [76/200]: Train Loss: 0.2321  |  Val Loss: 0.7528\n",
      "Epoch [77/200]: Train Loss: 0.2555  |  Val Loss: 0.7980\n",
      "Epoch [78/200]: Train Loss: 0.2792  |  Val Loss: 0.7210\n",
      "Epoch [79/200]: Train Loss: 0.1890  |  Val Loss: 0.8169\n",
      "Epoch [80/200]: Train Loss: 0.1709  |  Val Loss: 0.7818\n",
      "Epoch [81/200]: Train Loss: 0.1841  |  Val Loss: 0.8013\n",
      "Epoch [82/200]: Train Loss: 0.1765  |  Val Loss: 0.8319\n",
      "Epoch [83/200]: Train Loss: 0.1666  |  Val Loss: 0.8151\n",
      "Epoch [84/200]: Train Loss: 0.1623  |  Val Loss: 0.9496\n",
      "Epoch [85/200]: Train Loss: 0.1598  |  Val Loss: 0.8437\n",
      "Epoch [86/200]: Train Loss: 0.1520  |  Val Loss: 0.8759\n",
      "Epoch [87/200]: Train Loss: 0.1507  |  Val Loss: 0.9080\n",
      "Epoch [88/200]: Train Loss: 0.1561  |  Val Loss: 0.8819\n",
      "Epoch [89/200]: Train Loss: 0.1452  |  Val Loss: 0.9293\n",
      "Epoch [90/200]: Train Loss: 0.1565  |  Val Loss: 0.8743\n",
      "Epoch [91/200]: Train Loss: 0.1566  |  Val Loss: 0.8598\n",
      "Epoch [92/200]: Train Loss: 0.1478  |  Val Loss: 0.9222\n",
      "Epoch [93/200]: Train Loss: 0.1439  |  Val Loss: 0.9882\n",
      "Epoch [94/200]: Train Loss: 0.1415  |  Val Loss: 0.9112\n",
      "Epoch [95/200]: Train Loss: 0.2309  |  Val Loss: 0.9200\n",
      "Epoch [96/200]: Train Loss: 0.2831  |  Val Loss: 0.7566\n",
      "Epoch [97/200]: Train Loss: 0.1896  |  Val Loss: 0.9456\n",
      "Epoch [98/200]: Train Loss: 0.3553  |  Val Loss: 0.7167\n",
      "Epoch [99/200]: Train Loss: 0.3236  |  Val Loss: 0.7318\n",
      "Epoch [100/200]: Train Loss: 0.1662  |  Val Loss: 1.2606\n",
      "Epoch [101/200]: Train Loss: 0.1749  |  Val Loss: 0.9580\n",
      "Epoch [102/200]: Train Loss: 0.1671  |  Val Loss: 0.9102\n",
      "Epoch [103/200]: Train Loss: 0.2540  |  Val Loss: 0.9023\n",
      "Epoch [104/200]: Train Loss: 0.1533  |  Val Loss: 0.9396\n",
      "Epoch [105/200]: Train Loss: 0.1458  |  Val Loss: 0.9798\n",
      "Epoch [106/200]: Train Loss: 0.1499  |  Val Loss: 0.9349\n",
      "Epoch [107/200]: Train Loss: 0.1367  |  Val Loss: 1.0265\n",
      "Epoch [108/200]: Train Loss: 0.1328  |  Val Loss: 0.9601\n",
      "Epoch [109/200]: Train Loss: 0.1303  |  Val Loss: 1.0107\n",
      "Epoch [110/200]: Train Loss: 0.1299  |  Val Loss: 1.0566\n",
      "Epoch [111/200]: Train Loss: 0.1371  |  Val Loss: 1.0239\n",
      "Epoch [112/200]: Train Loss: 0.1288  |  Val Loss: 0.9988\n",
      "Epoch [113/200]: Train Loss: 0.1221  |  Val Loss: 1.0296\n",
      "Epoch [114/200]: Train Loss: 0.1290  |  Val Loss: 0.9526\n",
      "Epoch [115/200]: Train Loss: 0.1206  |  Val Loss: 1.0246\n",
      "Epoch [116/200]: Train Loss: 0.1313  |  Val Loss: 1.0394\n",
      "Epoch [117/200]: Train Loss: 0.1220  |  Val Loss: 1.0434\n",
      "Epoch [118/200]: Train Loss: 0.1147  |  Val Loss: 0.9834\n",
      "Epoch [119/200]: Train Loss: 0.1294  |  Val Loss: 1.0491\n",
      "Epoch [120/200]: Train Loss: 0.1266  |  Val Loss: 1.0125\n",
      "Epoch [121/200]: Train Loss: 0.1576  |  Val Loss: 1.0944\n",
      "Epoch [122/200]: Train Loss: 0.1712  |  Val Loss: 1.1154\n",
      "Epoch [123/200]: Train Loss: 0.2795  |  Val Loss: 1.4618\n",
      "Epoch [124/200]: Train Loss: 0.4646  |  Val Loss: 0.6619\n",
      "Epoch [125/200]: Train Loss: 0.3498  |  Val Loss: 0.5555\n",
      "Epoch [126/200]: Train Loss: 0.2111  |  Val Loss: 0.5883\n",
      "Epoch [127/200]: Train Loss: 0.1542  |  Val Loss: 0.6105\n",
      "Epoch [128/200]: Train Loss: 0.1425  |  Val Loss: 0.6954\n",
      "Epoch [129/200]: Train Loss: 0.1354  |  Val Loss: 0.7714\n",
      "Epoch [130/200]: Train Loss: 0.1444  |  Val Loss: 0.8822\n",
      "Epoch [131/200]: Train Loss: 0.1246  |  Val Loss: 0.9649\n",
      "Epoch [132/200]: Train Loss: 0.1171  |  Val Loss: 1.0592\n",
      "Epoch [133/200]: Train Loss: 0.1320  |  Val Loss: 1.0424\n",
      "Epoch [134/200]: Train Loss: 0.1464  |  Val Loss: 1.0028\n",
      "Epoch [135/200]: Train Loss: 0.1138  |  Val Loss: 1.1147\n",
      "Epoch [136/200]: Train Loss: 0.3066  |  Val Loss: 1.1091\n",
      "Epoch [137/200]: Train Loss: 0.2437  |  Val Loss: 0.9228\n",
      "Epoch [138/200]: Train Loss: 0.2380  |  Val Loss: 0.9674\n",
      "Epoch [139/200]: Train Loss: 0.2806  |  Val Loss: 0.6774\n",
      "Epoch [140/200]: Train Loss: 0.1794  |  Val Loss: 0.9038\n",
      "Epoch [141/200]: Train Loss: 0.1315  |  Val Loss: 0.6285\n",
      "Epoch [142/200]: Train Loss: 0.1338  |  Val Loss: 0.9804\n",
      "Epoch [143/200]: Train Loss: 0.1173  |  Val Loss: 0.9514\n",
      "Epoch [144/200]: Train Loss: 0.1126  |  Val Loss: 0.8978\n",
      "Epoch [145/200]: Train Loss: 0.0984  |  Val Loss: 0.8965\n",
      "Epoch [146/200]: Train Loss: 0.0928  |  Val Loss: 0.9299\n",
      "Epoch [147/200]: Train Loss: 0.0901  |  Val Loss: 0.9416\n",
      "Epoch [148/200]: Train Loss: 0.0840  |  Val Loss: 0.9537\n",
      "Epoch [149/200]: Train Loss: 0.0928  |  Val Loss: 0.9602\n",
      "Epoch [150/200]: Train Loss: 0.0764  |  Val Loss: 0.9821\n",
      "Epoch [151/200]: Train Loss: 0.0791  |  Val Loss: 1.0156\n",
      "Epoch [152/200]: Train Loss: 0.0945  |  Val Loss: 1.0098\n",
      "Epoch [153/200]: Train Loss: 0.0760  |  Val Loss: 1.0154\n",
      "Epoch [154/200]: Train Loss: 0.0805  |  Val Loss: 1.0123\n",
      "Epoch [155/200]: Train Loss: 0.0835  |  Val Loss: 1.1562\n",
      "Epoch [156/200]: Train Loss: 0.0967  |  Val Loss: 1.0883\n",
      "Epoch [157/200]: Train Loss: 0.0766  |  Val Loss: 1.0905\n",
      "Epoch [158/200]: Train Loss: 0.0701  |  Val Loss: 1.1658\n",
      "Epoch [159/200]: Train Loss: 0.0784  |  Val Loss: 1.0754\n",
      "Epoch [160/200]: Train Loss: 0.2776  |  Val Loss: 2.4870\n",
      "Epoch [161/200]: Train Loss: 0.6750  |  Val Loss: 1.0281\n",
      "Epoch [162/200]: Train Loss: 0.3750  |  Val Loss: 0.6146\n",
      "Epoch [163/200]: Train Loss: 0.2330  |  Val Loss: 0.8400\n",
      "Epoch [164/200]: Train Loss: 0.3000  |  Val Loss: 0.9229\n",
      "Epoch [165/200]: Train Loss: 0.1817  |  Val Loss: 0.8149\n",
      "Epoch [166/200]: Train Loss: 0.1198  |  Val Loss: 0.8645\n",
      "Epoch [167/200]: Train Loss: 0.1043  |  Val Loss: 0.9175\n",
      "Epoch [168/200]: Train Loss: 0.0956  |  Val Loss: 0.9767\n",
      "Epoch [169/200]: Train Loss: 0.0962  |  Val Loss: 0.9779\n",
      "Epoch [170/200]: Train Loss: 0.1136  |  Val Loss: 1.1851\n",
      "Epoch [171/200]: Train Loss: 0.1464  |  Val Loss: 1.0464\n",
      "Epoch [172/200]: Train Loss: 0.0845  |  Val Loss: 1.0845\n",
      "Epoch [173/200]: Train Loss: 0.0817  |  Val Loss: 1.1117\n",
      "Epoch [174/200]: Train Loss: 0.0808  |  Val Loss: 1.1136\n",
      "Epoch [175/200]: Train Loss: 0.0836  |  Val Loss: 1.0983\n",
      "Epoch [176/200]: Train Loss: 0.0719  |  Val Loss: 1.1093\n",
      "Epoch [177/200]: Train Loss: 0.0707  |  Val Loss: 1.1146\n",
      "Epoch [178/200]: Train Loss: 0.0642  |  Val Loss: 1.1398\n",
      "Epoch [179/200]: Train Loss: 0.0626  |  Val Loss: 1.1486\n",
      "Epoch [180/200]: Train Loss: 0.0722  |  Val Loss: 1.1641\n",
      "Epoch [181/200]: Train Loss: 0.0656  |  Val Loss: 1.1984\n",
      "Epoch [182/200]: Train Loss: 0.0562  |  Val Loss: 1.2036\n",
      "Epoch [183/200]: Train Loss: 0.0566  |  Val Loss: 1.1878\n",
      "Epoch [184/200]: Train Loss: 0.0512  |  Val Loss: 1.2274\n",
      "Epoch [185/200]: Train Loss: 0.0486  |  Val Loss: 1.2229\n",
      "Epoch [186/200]: Train Loss: 0.0515  |  Val Loss: 1.2617\n",
      "Epoch [187/200]: Train Loss: 0.0543  |  Val Loss: 1.2188\n",
      "Epoch [188/200]: Train Loss: 0.0573  |  Val Loss: 1.3458\n",
      "Epoch [189/200]: Train Loss: 0.0662  |  Val Loss: 1.2269\n",
      "Epoch [190/200]: Train Loss: 0.0784  |  Val Loss: 1.3478\n",
      "Epoch [191/200]: Train Loss: 0.0452  |  Val Loss: 1.3218\n",
      "Epoch [192/200]: Train Loss: 0.0434  |  Val Loss: 1.3462\n",
      "Epoch [193/200]: Train Loss: 0.0402  |  Val Loss: 1.3221\n",
      "Epoch [194/200]: Train Loss: 0.0356  |  Val Loss: 1.3427\n",
      "Epoch [195/200]: Train Loss: 0.0800  |  Val Loss: 1.3049\n",
      "Epoch [196/200]: Train Loss: 0.4041  |  Val Loss: 0.5671\n",
      "Epoch [197/200]: Train Loss: 0.2828  |  Val Loss: 1.0026\n",
      "Epoch [198/200]: Train Loss: 0.1369  |  Val Loss: 1.0814\n",
      "Epoch [199/200]: Train Loss: 0.0804  |  Val Loss: 1.1720\n",
      "Epoch [200/200]: Train Loss: 0.0713  |  Val Loss: 1.2087\n",
      "\n",
      "--- Resultados en Validación (final) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89        13\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.92        39\n",
      "   macro avg       0.93      0.93      0.93        39\n",
      "weighted avg       0.92      0.92      0.92        39\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[12  0  1]\n",
      " [ 0 12  0]\n",
      " [ 2  0 12]]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for X_batch, y_batch, A_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        A_batch = A_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch, A_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    val_loss, val_preds, val_labels = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]: \"\n",
    "          f\"Train Loss: {train_loss:.4f}  |  Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "print(\"\\n--- Resultados en Validación (final) ---\")\n",
    "print(classification_report(val_labels, val_preds))\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(confusion_matrix(val_labels, val_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def predict_sequences(model, csv_path, adjacency_matrix, label_map, device):\n",
    "    \"\"\"\n",
    "    Lee un CSV con columnas [Secuencia, X, Y, Z],\n",
    "    agrupa cada secuencia, hace padding y obtiene predicciones del modelo.\n",
    "    \n",
    "    Args:\n",
    "        model: modelo PyTorch entrenado (p.ej. STGCN).\n",
    "        csv_path: ruta al CSV a predecir.\n",
    "        adjacency_matrix: tensor (21, 21) usado en tu modelo.\n",
    "        label_map: diccionario, p.ej. {\"chau\": 0, \"hola\": 1, \"gracias\": 2}.\n",
    "        device: torch.device(\"cuda\" o \"cpu\").\n",
    "    \n",
    "    Returns:\n",
    "        Un diccionario {id_secuencia: clase_predicha_str}.\n",
    "    \"\"\"\n",
    "    # 1) Cargar CSV\n",
    "    df_test = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 2) Agrupar por secuencia y convertir a Tensor\n",
    "    grouped_test = df_test.groupby(\"Secuencia\").apply(\n",
    "        lambda x: torch.tensor(x[[\"X\", \"Y\", \"Z\"]].values, dtype=torch.float32)\n",
    "    )\n",
    "    # grouped_test es un Series donde cada elemento (fila) es un Tensor (num_filas, 3)\n",
    "\n",
    "    # 3) Hacer una lista con los tensores y aplicar pad_sequence\n",
    "    test_tensors = grouped_test.tolist()  # Lista de tensores\n",
    "    padded_test = pad_sequence(test_tensors, batch_first=True)\n",
    "    # => (num_secuencias, max_len, 3)\n",
    "\n",
    "    # 4) max_len debería ser (num_frames * 21). Verificamos y re-damos forma.\n",
    "    num_sequences = len(test_tensors)\n",
    "    max_len_test = padded_test.shape[1]\n",
    "    if max_len_test % 21 != 0:\n",
    "        raise ValueError(\n",
    "            \"La secuencia más larga no es múltiplo de 21. \"\n",
    "            \"Revisa la consistencia de tus datos (21 puntos por frame).\"\n",
    "        )\n",
    "    T_max = max_len_test // 21  # número de frames\n",
    "    \n",
    "    # 5) Redimensionar a (num_secuencias, T_max, 21, 3)\n",
    "    padded_test = padded_test.reshape(num_sequences, T_max, 21, 3).to(device)\n",
    "\n",
    "    # 6) Pasar por el modelo en modo evaluación\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Expande la matriz de adyacencia para tener (num_secuencias, 21, 21)\n",
    "        # En caso tu STGCN requiera 'A' con batch_size = num_secuencias\n",
    "        A_batch = adjacency_matrix.unsqueeze(0).repeat(num_sequences, 1, 1).to(device)\n",
    "        \n",
    "        outputs = model(padded_test, A_batch)  # (num_secuencias, num_clases)\n",
    "        preds = outputs.argmax(dim=1)          # (num_secuencias,)\n",
    "\n",
    "    # 7) Convertir índices predichos a nombres de clase\n",
    "    inv_label_map = {v: k for k, v in label_map.items()}  # inverso, ej: {0:\"chau\", 1:\"hola\", 2:\"gracias\"}\n",
    "    preds_names = [inv_label_map[p.item()] for p in preds]\n",
    "\n",
    "    # 8) Emparejar IDs de secuencia con la predicción\n",
    "    sequence_ids = grouped_test.index.tolist()  # IDs de secuencia en el mismo orden que 'padded_test'\n",
    "    results = dict(zip(sequence_ids, preds_names))\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manos detectadas: comenzando a capturar datos para la secuencia 1...\n",
      "Manos no detectadas: deteniendo la captura de la secuencia 1...\n",
      "Manos detectadas: comenzando a capturar datos para la secuencia 2...\n",
      "Manos no detectadas: deteniendo la captura de la secuencia 2...\n",
      "Manos detectadas: comenzando a capturar datos para la secuencia 3...\n",
      "Manos no detectadas: deteniendo la captura de la secuencia 3...\n",
      "Manos detectadas: comenzando a capturar datos para la secuencia 4...\n",
      "Manos no detectadas: deteniendo la captura de la secuencia 4...\n",
      "Manos detectadas: comenzando a capturar datos para la secuencia 5...\n",
      "Manos no detectadas: deteniendo la captura de la secuencia 5...\n",
      "Manos detectadas: comenzando a capturar datos para la secuencia 6...\n",
      "Manos no detectadas: deteniendo la captura de la secuencia 6...\n",
      "Manos detectadas: comenzando a capturar datos para la secuencia 7...\n",
      "Manos no detectadas: deteniendo la captura de la secuencia 7...\n",
      "Manos detectadas: comenzando a capturar datos para la secuencia 8...\n",
      "Manos no detectadas: deteniendo la captura de la secuencia 8...\n",
      "Manos detectadas: comenzando a capturar datos para la secuencia 9...\n",
      "Manos no detectadas: deteniendo la captura de la secuencia 9...\n",
      "Manos detectadas: comenzando a capturar datos para la secuencia 10...\n",
      "Manos no detectadas: deteniendo la captura de la secuencia 10...\n",
      "Manos detectadas: comenzando a capturar datos para la secuencia 11...\n",
      "Manos no detectadas: deteniendo la captura de la secuencia 11...\n",
      "Manos detectadas: comenzando a capturar datos para la secuencia 12...\n",
      "Manos no detectadas: deteniendo la captura de la secuencia 12...\n",
      "Manos detectadas: comenzando a capturar datos para la secuencia 13...\n",
      "Manos no detectadas: deteniendo la captura de la secuencia 13...\n",
      "Manos detectadas: comenzando a capturar datos para la secuencia 14...\n",
      "Manos no detectadas: deteniendo la captura de la secuencia 14...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "capturing = False\n",
    "sequence_id = 0 \n",
    "\n",
    "with open('datos_manos.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Secuencia', 'Mano', 'Punto', 'X', 'Y', 'Z'])\n",
    "\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "            results = holistic.process(image)\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "            mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "            if results.right_hand_landmarks or results.left_hand_landmarks:\n",
    "                if not capturing:\n",
    "                    sequence_id += 1 \n",
    "                    print(f\"Manos detectadas: comenzando a capturar datos para la secuencia {sequence_id}...\")\n",
    "                    capturing = True\n",
    "\n",
    "                if results.right_hand_landmarks:\n",
    "                    for idx, landmark in enumerate(results.right_hand_landmarks.landmark):\n",
    "                        writer.writerow([sequence_id, 'Derecha', idx, landmark.x, landmark.y, landmark.z])\n",
    "\n",
    "                if results.left_hand_landmarks:\n",
    "                    for idx, landmark in enumerate(results.left_hand_landmarks.landmark):\n",
    "                        writer.writerow([sequence_id, 'Izquierda', idx, landmark.x, landmark.y, landmark.z])\n",
    "\n",
    "            else:\n",
    "                if capturing:\n",
    "                    print(f\"Manos no detectadas: deteniendo la captura de la secuencia {sequence_id}...\")\n",
    "                    capturing = False\n",
    "\n",
    "            cv2.imshow('Video desde PC - Holistic', image)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'): # Salir con la tecla 'q'\n",
    "                break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas a tiempo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secuencia 1 -> predicción: chau\n",
      "Secuencia 2 -> predicción: chau\n",
      "Secuencia 3 -> predicción: chau\n",
      "Secuencia 4 -> predicción: chau\n",
      "Secuencia 5 -> predicción: chau\n",
      "Secuencia 6 -> predicción: chau\n",
      "Secuencia 7 -> predicción: chau\n",
      "Secuencia 8 -> predicción: chau\n",
      "Secuencia 9 -> predicción: chau\n",
      "Secuencia 10 -> predicción: chau\n",
      "Secuencia 11 -> predicción: chau\n",
      "Secuencia 12 -> predicción: chau\n",
      "Secuencia 13 -> predicción: chau\n",
      "Secuencia 14 -> predicción: chau\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sorac\\AppData\\Local\\Temp\\ipykernel_17488\\1166589002.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  adjacency_matrix = torch.tensor(adjacency_matrix, dtype=torch.float32)\n",
      "C:\\Users\\sorac\\AppData\\Local\\Temp\\ipykernel_17488\\2817061340.py:24: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_test = df_test.groupby(\"Secuencia\").apply(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "adjacency_matrix = torch.tensor(adjacency_matrix, dtype=torch.float32)\n",
    "adjacency_matrix = adjacency_matrix.to(device)\n",
    "\n",
    "test_csv_path = \"test_chau.csv\" \n",
    "predicciones = predict_sequences(\n",
    "    model,\n",
    "    test_csv_path,\n",
    "    adjacency_matrix,\n",
    "    label_map,\n",
    "    device\n",
    ")\n",
    "\n",
    "for seq_id, clase_pred in predicciones.items():\n",
    "    print(f\"Secuencia {seq_id} -> predicción: {clase_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(predicciones.items(), columns=[\"Secuencia\", \"Clase Predicha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Predicciones'}, xlabel='Clase Predicha'>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds[\"Clase Predicha\"].value_counts().plot(kind=\"bar\", title=\"Predicciones\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
